{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline  \n",
    "print (\"Packages loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download the text and make corpus (set of words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download (or reuse) the text file that we will use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "folder_dir  = \"data\"\n",
    "file_name   = \"text8.zip\"\n",
    "file_path   = os.path.join(folder_dir, file_name)\n",
    "url         = 'http://mattmahoney.net/dc/'\n",
    "if not os.path.exists(file_path):\n",
    "    print (\"No file found. Start downloading\")\n",
    "    downfilename, _ = urllib.request.urlretrieve(\n",
    "        url + file_name, file_path)\n",
    "    print (\"'%s' downloaded\" % (downfilename))\n",
    "else:\n",
    "    print (\"File already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check we have correct data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I guess we have correct file at 'data\\text8.zip'\n"
     ]
    }
   ],
   "source": [
    "statinfo = os.stat(file_path)\n",
    "expected_bytes = 31344016\n",
    "if statinfo.st_size == expected_bytes:\n",
    "    print (\"I guess we have correct file at '%s'\" % (file_path))\n",
    "else:\n",
    "    print (\"Something's wrong with the file at '%s'\" % (file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with zipfile.ZipFile(filename) as f:\n",
    "        data = f.read(f.namelist()[0]).split()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'words' is <class 'list'> / Length is 17005207 \n'words' look like \n [b'anarchism', b'originated', b'as', b'a', b'term', b'of', b'abuse', b'first', b'used', b'against', b'early', b'working', b'class', b'radicals', b'including', b'the', b'diggers', b'of', b'the', b'english', b'revolution', b'and', b'the', b'sans', b'culottes', b'of', b'the', b'french', b'revolution', b'whilst', b'the', b'term', b'is', b'still', b'used', b'in', b'a', b'pejorative', b'way', b'to', b'describe', b'any', b'act', b'that', b'used', b'violent', b'means', b'to', b'destroy', b'the', b'organization', b'of', b'society', b'it', b'has', b'also', b'been', b'taken', b'up', b'as', b'a', b'positive', b'label', b'by', b'self', b'defined', b'anarchists', b'the', b'word', b'anarchism', b'is', b'derived', b'from', b'the', b'greek', b'without', b'archons', b'ruler', b'chief', b'king', b'anarchism', b'as', b'a', b'political', b'philosophy', b'is', b'the', b'belief', b'that', b'rulers', b'are', b'unnecessary', b'and', b'should', b'be', b'abolished', b'although', b'there', b'are', b'differing']\n"
     ]
    }
   ],
   "source": [
    "words = read_data(file_path) \n",
    "print (\"Type of 'words' is %s / Length is %d \" \n",
    "       % (type(words), len(words)))\n",
    "print (\"'words' look like \\n %s\" %(words[0:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2. Make a dictionary with fixed length (using UNK token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'count' is <class 'list'> / Length is 50000 \n'count' looks like \n [['UNK', -1], (b'the', 1061396), (b'of', 593677), (b'and', 416629), (b'one', 411764), (b'in', 372201), (b'a', 325873), (b'to', 316376), (b'zero', 264975), (b'nine', 250430)]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 50000 \n",
    "count = [['UNK', -1]] \n",
    "count.extend(collections.Counter(words)\n",
    "             .most_common(vocabulary_size - 1)) # -1 is for UNK \n",
    "print (\"Type of 'count' is %s / Length is %d \" % (type(count), len(count)))\n",
    "print (\"'count' looks like \\n %s\" % (count[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'dictionary' is <class 'dict'> / Length is 50000 \n"
     ]
    }
   ],
   "source": [
    "dictionary = dict() \n",
    "for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "print (\"Type of 'dictionary' is %s / Length is %d \" \n",
    "       % (type(dictionary), len(dictionary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a reverse dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "print (\"Type of 'reverse_dictionary' is %s / Length is %d \" \n",
    "       % (type(reverse_dictionary), len(reverse_dictionary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "unk_count = 0\n",
    "for word in words:\n",
    "    if word in dictionary:\n",
    "        index = dictionary[word]\n",
    "    else:\n",
    "        index = 0  # dictionary['UNK']\n",
    "        unk_count += 1\n",
    "    data.append(index)\n",
    "count[0][1] = unk_count\n",
    "# del words  # Hint to reduce memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'dictionary' converts word to index \n",
    "### 'reverse_dictionary' converts index to word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) are: [['UNK', 418391], (b'the', 1061396), (b'of', 593677), (b'and', 416629), (b'one', 411764)]\n"
     ]
    }
   ],
   "source": [
    "print (\"Most common words (+UNK) are: %s\" % (count[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data (in indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data: [5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156]\n"
     ]
    }
   ],
   "source": [
    "print (\"Sample data: %s\" % (data[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to char (which we can read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data corresponds to\n__________________\n5234->b'anarchism'\n3081->b'originated'\n12->b'as'\n6->b'a'\n195->b'term'\n2->b'of'\n3134->b'abuse'\n46->b'first'\n59->b'used'\n156->b'against'\n"
     ]
    }
   ],
   "source": [
    "print (\"Sample data corresponds to\\n__________________\")\n",
    "for i in range(10):\n",
    "    print (\"%d->%s\" % (data[i], reverse_dictionary[data[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch-generating function for skip-gram model\n",
    "## - Skip-gram (one word to one word) => Can generate more training data\n",
    "\n",
    "<img src=\"images/etc/word2vec_desc.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch  = np.ndarray(shape=(batch_size),    dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1 # [ skip_window target skip_window ]\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    for i in range(batch_size // num_skips): # '//' makes the result an integer, e.g., 7//3 = 2\n",
    "        target = skip_window\n",
    "        targets_to_avoid = [ skip_window ]\n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span - 1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[target]\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples for generating batch and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'batch' is <class 'numpy.ndarray'> / Length is 8 \nType of 'labels' is <class 'numpy.ndarray'> / Length is 8 \n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "batch, labels = generate_batch(batch_size=8, num_skips=2, skip_window=1)\n",
    "print (\"Type of 'batch' is %s / Length is %d \" \n",
    "       % (type(batch), len(batch))) \n",
    "print (\"Type of 'labels' is %s / Length is %d \" \n",
    "       % (type(labels), len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'batch' looks like \n [3081 3081   12   12    6    6  195  195]\n"
     ]
    }
   ],
   "source": [
    "print (\"'batch' looks like \\n %s\" % (batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'labels' looks like \n [[5234]\n [  12]\n [   6]\n [3081]\n [  12]\n [ 195]\n [   2]\n [   6]]\n"
     ]
    }
   ],
   "source": [
    "print (\"'labels' looks like \\n %s\" % (labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3081 -> 5234\n\tb'originated' -> b'anarchism'\n3081 -> 12\n\tb'originated' -> b'as'\n12 -> 6\n\tb'as' -> b'a'\n12 -> 3081\n\tb'as' -> b'originated'\n6 -> 12\n\tb'a' -> b'as'\n6 -> 195\n\tb'a' -> b'term'\n195 -> 2\n\tb'term' -> b'of'\n195 -> 6\n\tb'term' -> b'a'\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print (\"%d -> %d\" \n",
    "           % (batch[i], labels[i, 0])),\n",
    "    print (\"\\t%s -> %s\" \n",
    "           % (reverse_dictionary[batch[i]]\n",
    "              , reverse_dictionary[labels[i, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build a Skip-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters ready\n"
     ]
    }
   ],
   "source": [
    "batch_size     = 128\n",
    "embedding_size = 128       # Dimension of the embedding vector.\n",
    "skip_window    = 1         # How many words to consider left and right.\n",
    "num_skips      = 2         # How many times to reuse an input \n",
    "print (\"Parameters ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6 181  77 104  40   5 166  56 155 138  39 127 195 192 143  86 123  80\n  97  38  33 102   8   1 142  61 199 121 133  99 145 129]\n"
     ]
    }
   ],
   "source": [
    "# Random validation set to sample nearest neighbors.\n",
    "valid_size     = 32        # Random set of words to evaluate similarity \n",
    "valid_window   = 200       # Only pick validation samples in the top 200\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "\n",
    "print (valid_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network ready\n"
     ]
    }
   ],
   "source": [
    "# Construct the word2vec model \n",
    "train_inputs   = tf.placeholder(tf.int32, shape=[batch_size])   \n",
    "train_labels   = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "valid_dataset  = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "# Look up embeddings for inputs. (vocabulary_size = 50,000)\n",
    "with tf.variable_scope(\"EMBEDDING\"):\n",
    "    with tf.device('/cpu:0'):\n",
    "        embeddings = tf.Variable(\n",
    "            tf.random_uniform([vocabulary_size, embedding_size]\n",
    "                              , -1.0, 1.0))\n",
    "        embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "    \n",
    "# Construct the variables for the NCE loss\n",
    "with tf.variable_scope(\"NCE_WEIGHT\"):\n",
    "    nce_weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                            stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "print (\"Network ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-26f6bd7dd78f>:10: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\nInstructions for updating:\nkeep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions Ready\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # Loss function \n",
    "    num_sampled = 64        # Number of negative examples to sample. \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.nce_loss(nce_weights, nce_biases\n",
    "                       , train_labels, embed, num_sampled, vocabulary_size))\n",
    "    # Optimizer\n",
    "    optm = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "    # Similarity measure (important)\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings\n",
    "                    , valid_dataset)\n",
    "    siml = tf.matmul(valid_embeddings, normalized_embeddings\n",
    "                    , transpose_b=True)\n",
    "    \n",
    "print (\"Functions Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train a Skip-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 0 is 0.148\nNearest to 'b'a'': 'b'believer'', 'b'smoke'', 'b'widely'', 'b'amour'', 'b'quinn'', 'b'tens'',\nNearest to 'b'series'': 'b'firebird'', 'b'tremendously'', 'b'honeybees'', 'b'footsteps'', 'b'elicit'', 'b'renderer'',\nNearest to 'b'however'': 'b'longwave'', 'b'tansley'', 'b'pestilence'', 'b'provably'', 'b'risk'', 'b'jag'',\nNearest to 'b'then'': 'b'brutal'', 'b'fertilize'', 'b'steam'', 'b'quenched'', 'b'unrestricted'', 'b'peh'',\nNearest to 'b'were'': 'b'edinburgh'', 'b'replicators'', 'b'xlii'', 'b'template'', 'b'dividends'', 'b'truthfulness'',\nNearest to 'b'in'': 'b'kabbalistic'', 'b'cpl'', 'b'eprint'', 'b'monastic'', 'b'persuasion'', 'b'skits'',\nNearest to 'b'music'': 'b'tabular'', 'b'backward'', 'b'striping'', 'b'cambodians'', 'b'caeiro'', 'b'distrusted'',\nNearest to 'b'many'': 'b'administrators'', 'b'materialism'', 'b'logone'', 'b'rodgers'', 'b'helena'', 'b'hoare'',\nNearest to 'b't'': 'b'frantz'', 'b'attributing'', 'b'authorities'', 'b'resemblances'', 'b'warring'', 'b'buyout'',\nNearest to 'b'each'': 'b'delay'', 'b'yassin'', 'b'county'', 'b'volunteering'', 'b'dyslexia'', 'b'coca'',\nNearest to 'b'have'': 'b'integrate'', 'b'wreckin'', 'b'ecological'', 'b'bets'', 'b'implications'', 'b'remarking'',\nNearest to 'b'university'': 'b'couplet'', 'b'raped'', 'b'jarrett'', 'b'masoretes'', 'b'mitch'', 'b'agile'',\nNearest to 'b'term'': 'b'shaky'', 'b'hattie'', 'b'grimaldi'', 'b'mummified'', 'b'pompeius'', 'b'uighur'',\nNearest to 'b'until'': 'b'ralston'', 'b'xv'', 'b'minoan'', 'b'bower'', 'b'davis'', 'b'junichiro'',\nNearest to 'b'several'': 'b'workday'', 'b'misnomer'', 'b'breath'', 'b'satisfied'', 'b'trafalgar'', 'b'disarmed'',\nNearest to 'b'united'': 'b'screaming'', 'b'prohibition'', 'b'occasioned'', 'b'shoes'', 'b'bnetd'', 'b'kanembu'',\nNearest to 'b'century'': 'b'valera'', 'b'innate'', 'b'ferns'', 'b'lui'', 'b'americium'', 'b'asymptomatic'',\nNearest to 'b'over'': 'b'outmoded'', 'b'clothed'', 'b'ddt'', 'b'cunning'', 'b'construed'', 'b'bourne'',\nNearest to 'b'will'': 'b'strangely'', 'b'mazarin'', 'b'braintree'', 'b'dart'', 'b'belarusian'', 'b'lowe'',\nNearest to 'b'not'': 'b'abv'', 'b'tally'', 'b'amount'', 'b'fontane'', 'b'prog'', 'b'linear'',\nNearest to 'b'this'': 'b'hangman'', 'b'biruni'', 'b'ramesses'', 'b'martyr'', 'b'chlorides'', 'b'acquiring'',\nNearest to 'b'being'': 'b'stepping'', 'b'walters'', 'b'masterminded'', 'b'showed'', 'b'unworkable'', 'b'teaching'',"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nNearest to 'b'zero'': 'b'payable'', 'b'spit'', 'b'rubies'', 'b'justifiably'', 'b'mnp'', 'b'riots'',\nNearest to 'b'the'': 'b'oscar'', 'b'novi'', 'b'shades'', 'b'hershey'', 'b'ecu'', 'b'stationary'',\nNearest to 'b'although'': 'b'whiteness'', 'b'determinants'', 'b'ellipse'', 'b'unwind'', 'b'posthuman'', 'b'skiing'',\nNearest to 'b'after'': 'b'slick'', 'b'mayotte'', 'b'replace'', 'b'platoon'', 'b'festival'', 'b'shroud'',\nNearest to 'b'found'': 'b'biochemist'', 'b'sentenced'', 'b'roosevelt'', 'b'alde'', 'b'punjab'', 'b'geometrically'',\nNearest to 'b'name'': 'b'hoppers'', 'b'zapata'', 'b'ericales'', 'b'beti'', 'b'sublimation'', 'b'morally'',\nNearest to 'b'same'': 'b'loos'', 'b'liam'', 'b'opus'', 'b'instrument'', 'b'steamship'', 'b'commit'',\nNearest to 'b'while'': 'b'inaction'', 'b'majdanek'', 'b'lured'', 'b'alto'', 'b'started'', 'b'contend'',\nNearest to 'b'john'': 'b'bomb'', 'b'paxton'', 'b'stays'', 'b'ias'', 'b'arcseconds'', 'b'andros'',\nNearest to 'b'life'': 'b'shaughnessy'', 'b'lydia'', 'b'confiscation'', 'b'lackey'', 'b'unsophisticated'', 'b'darth'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 2000 is 113.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 4000 is 53.073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 6000 is 33.435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 8000 is 23.608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 10000 is 18.132\nNearest to 'b'a'': 'b'the'', 'b'austin'', 'b'reginae'', 'b'zulu'', 'b'phi'', 'b'it'',\nNearest to 'b'series'': 'b'matter'', 'b'footsteps'', 'b'home'', 'b'movies'', 'b'gland'', 'b'filippo'',\nNearest to 'b'however'': 'b'risk'', 'b'pestilence'', 'b'pka'', 'b'imaginary'', 'b'reginae'', 'b'analogy'',\nNearest to 'b'then'': 'b'steam'', 'b'brutal'', 'b'reginae'', 'b'guide'', 'b'androids'', 'b'thai'',\nNearest to 'b'were'': 'b'vs'', 'b'and'', 'b'canaris'', 'b'pneumonia'', 'b'happening'', 'b'work'',\nNearest to 'b'in'': 'b'of'', 'b'and'', 'b'basins'', 'b'by'', 'b'vs'', 'b'with'',\nNearest to 'b'music'': 'b'backward'', 'b'wilmot'', 'b'title'', 'b'christians'', 'b'nih'', 'b'computer'',\nNearest to 'b'many'': 'b'hoare'', 'b'administrators'', 'b'alchemists'', 'b'despite'', 'b'nfl'', 'b'materialism'',\nNearest to 'b't'': 'b'widely'', 'b'for'', 'b'authorities'', 'b'altenberg'', 'b'suffix'', 'b'mond'',\nNearest to 'b'each'': 'b'analogue'', 'b'farm'', 'b'vs'', 'b'box'', 'b'anarchist'', 'b'their'',\nNearest to 'b'have'': 'b'be'', 'b'is'', 'b'absorbed'', 'b'austin'', 'b'module'', 'b'jump'',\nNearest to 'b'university'': 'b'wins'', 'b'raped'', 'b'austria'', 'b'rd'', 'b'sh'', 'b'topological'',\nNearest to 'b'term'': 'b'jpg'', 'b'grimaldi'', 'b'ethnic'', 'b'organic'', 'b'career'', 'b'stresses'',\nNearest to 'b'until'': 'b'davis'', 'b'hogeschool'', 'b'korea'', 'b'taste'', 'b'tubing'', 'b'var'',\nNearest to 'b'several'': 'b'breath'', 'b'approved'', 'b'zero'', 'b'closure'', 'b'austin'', 'b'satisfied'',\nNearest to 'b'united'': 'b'austin'', 'b'prohibition'', 'b'given'', 'b'alien'', 'b'shoes'', 'b'wallpaper'',\nNearest to 'b'century'': 'b'americium'', 'b'sigma'', 'b'hitler'', 'b'invading'', 'b'gland'', 'b'six'',\nNearest to 'b'over'': 'b'charcot'', 'b'activated'', 'b'forests'', 'b'two'', 'b'axis'', 'b'diomedes'',\nNearest to 'b'will'': 'b'strangely'', 'b'gland'', 'b'dart'', 'b'ginsberg'', 'b'psychoanalysis'', 'b'contacted'',\nNearest to 'b'not'': 'b'it'', 'b'pleasant'', 'b'skater'', 'b'also'', 'b'there'', 'b'anxiety'',\nNearest to 'b'this'': 'b'the'', 'b'malaysia'', 'b'chlorides'', 'b'a'', 'b'respected'', 'b'interview'',\nNearest to 'b'being'': 'b'mathbf'', 'b'chemical'', 'b'showed'', 'b'powerbook'', 'b'any'', 'b'france'',\nNearest to 'b'zero'': 'b'nine'', 'b'austin'', 'b'amo'', 'b'vs'', 'b'six'', 'b'reginae'',\nNearest to 'b'the'': 'b'a'', 'b'reginae'', 'b'his'', 'UNK', 'b'and'', 'b'this'',\nNearest to 'b'although'': 'b'system'', 'b'lt'', 'b'serve'', 'b'mya'', 'b'reviews'', 'b'tales'',\nNearest to 'b'after'': 'b'replace'', 'b'phi'', 'b'festival'', 'b'unnatural'', 'b'special'', 'b'austin'',\nNearest to 'b'found'': 'b'biochemist'', 'b'austin'', 'b'roosevelt'', 'b'founder'', 'b'sentenced'', 'b'bang'',\nNearest to 'b'name'': 'b'evil'', 'b'product'', 'b'saints'', 'b'appearance'', 'b'ari'', 'b'slaves'',\nNearest to 'b'same'': 'b'find'', 'b'opus'', 'b'instrument'', 'b'vs'', 'b'commit'', 'b'through'',\nNearest to 'b'while'': 'b'started'', 'b'nine'', 'b'familial'', 'b'ambrose'', 'b'dose'', 'b'alto'',\nNearest to 'b'john'': 'b'bomb'', 'b'fifteen'', 'b'gland'', 'b'drawn'', 'b'amo'', 'b'breast'',\nNearest to 'b'life'': 'b'vs'', 'b'amo'', 'b'austin'', 'b'sculpture'', 'b'selznick'', 'b'psi'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 12000 is 13.910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 14000 is 11.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 16000 is 9.781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 18000 is 8.591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 20000 is 7.749\nNearest to 'b'a'': 'b'the'', 'b'and'', 'b'this'', 'b'albuquerque'', 'b'msg'', 'b'it'',\nNearest to 'b'series'': 'b'matter'', 'b'footsteps'', 'b'movies'', 'b'home'', 'b'fictitious'', 'b'cinque'',\nNearest to 'b'however'': 'b'pestilence'', 'b'imaginary'', 'b'risk'', 'b'numa'', 'b'agouti'', 'b'reginae'',\nNearest to 'b'then'': 'b'agouti'', 'b'steam'', 'b'androids'', 'b'reginae'', 'b'guide'', 'b'provide'',\nNearest to 'b'were'': 'b'are'', 'b'was'', 'b'is'', 'b'vs'', 'b'canaris'', 'b'and'',\nNearest to 'b'in'': 'b'and'', 'b'at'', 'b'from'', 'b'on'', 'b'of'', 'b'with'',\nNearest to 'b'music'': 'b'backward'', 'b'solon'', 'b'wilmot'', 'b'alt'', 'b'christians'', 'b'distrusted'',\nNearest to 'b'many'': 'b'some'', 'b'administrators'', 'b'hoare'', 'b'despite'', 'b'alchemists'', 'b'dasyprocta'',\nNearest to 'b't'': 'b'widely'', 'b'suffix'', 'b'reasonably'', 'b'authorities'', 'b'altenberg'', 'b'proclaimed'',\nNearest to 'b'each'': 'b'their'', 'b'analogue'', 'b'farm'', 'b'box'', 'b'therapists'', 'b'hbox'',\nNearest to 'b'have'': 'b'be'', 'b'had'', 'b'has'', 'b'absorbed'', 'b'princes'', 'b'agouti'',\nNearest to 'b'university'': 'b'raped'', 'b'wins'', 'b'austria'', 'b'topological'', 'b'alphorn'', 'b'rd'',\nNearest to 'b'term'': 'b'grimaldi'', 'b'jpg'', 'b'stresses'', 'b'agouti'', 'b'career'', 'b'ethnic'',\nNearest to 'b'until'': 'b'xv'', 'b'dmt'', 'b'compiler'', 'b'before'', 'b'from'', 'b'minoan'',\nNearest to 'b'several'': 'b'breath'', 'b'approved'', 'b'closure'', 'b'misnomer'', 'b'manifest'', 'b'satisfied'',\nNearest to 'b'united'': 'b'dasyprocta'', 'b'prohibition'', 'b'austin'', 'b'from'', 'b'wallpaper'', 'b'bowhunting'',\nNearest to 'b'century'': 'b'americium'', 'b'sigma'', 'b'cit'', 'b'invading'', 'b'agouti'', 'b'alphorn'',\nNearest to 'b'over'': 'b'activated'', 'b'charcot'', 'b'forests'', 'b'two'', 'b'warriors'', 'b'afonso'',\nNearest to 'b'will'': 'b'strangely'', 'b'would'', 'b'cinque'', 'b'numa'', 'b'psychoanalysis'', 'b'debts'',\nNearest to 'b'not'': 'b'it'', 'b'also'', 'b'there'', 'b'pleasant'', 'b'abv'', 'b'skater'',\nNearest to 'b'this'': 'b'the'', 'b'it'', 'b'a'', 'b'malaysia'', 'b'that'', 'b'which'',\nNearest to 'b'being'': 'b'any'', 'b'foo'', 'b'showed'', 'b'entropy'', 'b'unworkable'', 'b'powerbook'',\nNearest to 'b'zero'': 'b'nine'', 'b'eight'', 'b'six'', 'b'seven'', 'b'five'', 'b'four'',\nNearest to 'b'the'': 'b'a'', 'b'his'', 'b'its'', 'b'this'', 'b'one'', 'b'reginae'',\nNearest to 'b'although'': 'b'tales'', 'b'dasyprocta'', 'b'agouti'', 'b'lt'', 'b'ellipse'', 'b'chasing'',\nNearest to 'b'after'': 'b'replace'', 'b'unnatural'', 'b'in'', 'b'if'', 'b'aquila'', 'b'phi'',\nNearest to 'b'found'': 'b'biochemist'', 'b'sentenced'', 'b'founder'', 'b'austin'', 'b'roosevelt'', 'b'bang'',\nNearest to 'b'name'': 'b'agouti'', 'b'appearance'', 'b'ari'', 'b'evil'', 'b'product'', 'b'homozygous'',\nNearest to 'b'same'': 'b'opus'', 'b'find'', 'b'through'', 'b'agouti'', 'b'circ'', 'b'instrument'',\nNearest to 'b'while'': 'b'started'', 'b'and'', 'b'ambrose'', 'b'bolt'', 'b'alto'', 'b'familial'',\nNearest to 'b'john'': 'b'bomb'', 'b'henri'', 'b'paxton'', 'b'fifteen'', 'b'autonomy'', 'b'and'',\nNearest to 'b'life'': 'b'lydia'', 'b'msg'', 'b'vs'', 'b'amo'', 'b'sculpture'', 'b'josef'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 22000 is 7.153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 24000 is 7.035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 26000 is 6.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 28000 is 6.243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 30000 is 6.144\nNearest to 'b'a'': 'b'the'', 'b'akita'', 'b'albuquerque'', 'b'trinomial'', 'b'this'', 'b'austin'',\nNearest to 'b'series'': 'b'cpc'', 'b'footsteps'', 'b'matter'', 'b'fictitious'', 'b'movies'', 'b'umayyad'',\nNearest to 'b'however'': 'b'jag'', 'b'pestilence'', 'b'imaginary'', 'b'and'', 'b'agouti'', 'b'analogy'',\nNearest to 'b'then'': 'b'agouti'', 'b'androids'', 'b'reginae'', 'b'unofficially'', 'b'guide'', 'b'that'',\nNearest to 'b'were'': 'b'are'', 'b'was'', 'b'is'', 'b'have'', 'b'canaris'', 'b'vs'',\nNearest to 'b'in'': 'b'at'', 'b'on'', 'b'and'', 'b'of'', 'b'from'', 'b'nine'',\nNearest to 'b'music'': 'b'backward'', 'b'trinomial'', 'b'solon'', 'b'compressibility'', 'b'wilmot'', 'b'thermometer'',\nNearest to 'b'many'': 'b'some'', 'b'the'', 'b'administrators'', 'b'despite'', 'b'hoare'', 'b'alchemists'',\nNearest to 'b't'': 'b'dewey'', 'b'amalthea'', 'b'widely'', 'b'authorities'', 'b'suffix'', 'b'altenberg'',\nNearest to 'b'each'': 'b'their'', 'b'agra'', 'b'primigenius'', 'b'analogue'', 'b'farm'', 'b'therapists'',\nNearest to 'b'have'': 'b'be'', 'b'had'', 'b'has'', 'b'are'', 'b'absorbed'', 'b'were'',\nNearest to 'b'university'': 'b'couplet'', 'b'raped'', 'b'austria'', 'b'wins'', 'b'topological'', 'b'nottingham'',\nNearest to 'b'term'': 'b'grimaldi'', 'b'stresses'', 'b'abet'', 'b'career'', 'b'organic'', 'b'name'',\nNearest to 'b'until'': 'b'xv'', 'b'from'', 'b'before'', 'b'in'', 'b'minoan'', 'b'at'',\nNearest to 'b'several'': 'b'breath'', 'b'approved'', 'b'closure'', 'b'commitments'', 'b'the'', 'b'misnomer'',\nNearest to 'b'united'': 'b'from'', 'b'prohibition'', 'b'dasyprocta'', 'b'trinomial'', 'b'bowhunting'', 'b'wallpaper'',\nNearest to 'b'century'': 'b'invading'', 'b'six'', 'b'cit'', 'b'innate'', 'b'refectory'', 'b'eg'',\nNearest to 'b'over'': 'b'activated'', 'b'charcot'', 'b'cunning'', 'b'clothed'', 'b'ivy'', 'b'for'',\nNearest to 'b'will'': 'b'would'', 'b'can'', 'b'strangely'', 'b'quakers'', 'b'numa'', 'b'debts'',\nNearest to 'b'not'': 'b'it'', 'b'also'', 'b'there'', 'b'they'', 'b'to'', 'b'skater'',\nNearest to 'b'this'': 'b'it'', 'b'the'', 'b'a'', 'b'which'', 'b'that'', 'b'akita'',\nNearest to 'b'being'': 'b'akh'', 'b'any'', 'b'lumi'', 'b'foo'', 'b'entropy'', 'b'unworkable'',\nNearest to 'b'zero'': 'b'eight'', 'b'six'', 'b'five'', 'b'nine'', 'b'seven'', 'b'four'',\nNearest to 'b'the'': 'b'a'', 'b'his'', 'b'their'', 'b'its'', 'b'this'', 'b'some'',\nNearest to 'b'although'': 'b'while'', 'b'dasyprocta'', 'b'is'', 'b'gaming'', 'b'abitibi'', 'b'does'',\nNearest to 'b'after'': 'b'in'', 'b'replace'', 'b'at'', 'b'if'', 'b'sdk'', 'b'unnatural'',\nNearest to 'b'found'': 'b'biochemist'', 'b'trinomial'', 'b'sentenced'', 'b'trek'', 'b'austin'', 'b'bang'',\nNearest to 'b'name'': 'b'agouti'', 'b'appearance'', 'b'pixel'', 'b'ari'', 'b'product'', 'b'evil'',\nNearest to 'b'same'': 'b'opus'', 'b'through'', 'b'find'', 'b'akita'', 'b'to'', 'b'loos'',\nNearest to 'b'while'': 'b'and'', 'b'started'', 'b'ambrose'', 'b'is'', 'b'alto'', 'b'bolt'',\nNearest to 'b'john'': 'b'bomb'', 'b'paxton'', 'b'henri'', 'b'fifteen'', 'b'strata'', 'b'autonomy'',\nNearest to 'b'life'': 'b'bos'', 'b'abakan'', 'b'lydia'', 'b'msg'', 'b'amo'', 'b'heywood'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 32000 is 5.883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 34000 is 5.886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 36000 is 5.681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 38000 is 5.240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 40000 is 5.460\nNearest to 'b'a'': 'b'the'', 'b'akita'', 'b'johansen'', 'b'austin'', 'b'zulu'', 'b'trinomial'',\nNearest to 'b'series'': 'b'cpc'', 'b'footsteps'', 'b'fictitious'', 'b'umayyad'', 'b'matter'', 'b'rick'',\nNearest to 'b'however'': 'b'and'', 'b'imaginary'', 'b'pestilence'', 'b'jag'', 'b'adamantium'', 'b'agouti'',\nNearest to 'b'then'': 'b'agouti'', 'b'that'', 'b'reginae'', 'b'unofficially'', 'b'androids'', 'b'akita'',\nNearest to 'b'were'': 'b'are'', 'b'was'', 'b'is'', 'b'have'', 'b'be'', 'b'had'',\nNearest to 'b'in'': 'b'at'', 'b'and'', 'b'on'', 'b'from'', 'b'with'', 'b'crandall'',\nNearest to 'b'music'': 'b'backward'', 'b'trinomial'', 'b'compressibility'', 'b'solon'', 'b'thermometer'', 'b'recitative'',\nNearest to 'b'many'': 'b'some'', 'b'recitative'', 'b'these'', 'b'administrators'', 'b'despite'', 'b'hoare'',\nNearest to 'b't'': 'b'dewey'', 'b'warring'', 'b'reasonably'', 'b'widely'', 'b'amalthea'', 'b'suffix'',\nNearest to 'b'each'': 'b'their'', 'b'the'', 'b'armageddon'', 'b'agra'', 'b'farm'', 'b'therapists'',\nNearest to 'b'have'': 'b'had'', 'b'be'', 'b'has'', 'b'were'', 'b'are'', 'b'absorbed'',\nNearest to 'b'university'': 'b'couplet'', 'b'raped'', 'b'austria'', 'b'wins'', 'b'topological'', 'b'aveiro'',\nNearest to 'b'term'': 'b'grimaldi'', 'b'stresses'', 'b'name'', 'b'abet'', 'b'hattie'', 'b'agouti'',\nNearest to 'b'until'': 'b'xv'', 'b'before'', 'b'from'', 'b'at'', 'b'compiler'', 'b'two'',\nNearest to 'b'several'': 'b'breath'', 'b'many'', 'b'approved'', 'b'commitments'', 'b'closure'', 'b'stitch'',\nNearest to 'b'united'': 'b'from'', 'b'prohibition'', 'b'dasyprocta'', 'b'bowhunting'', 'b'trinomial'', 'b'austin'',\nNearest to 'b'century'': 'b'keg'', 'b'innate'', 'b'invading'', 'b'cit'', 'b'eg'', 'b'refectory'',\nNearest to 'b'over'': 'b'activated'', 'b'charcot'', 'b'cunning'', 'b'microseconds'', 'b'four'', 'b'ivy'',\nNearest to 'b'will'': 'b'would'', 'b'can'', 'b'strangely'', 'b'belarusian'', 'b'quakers'', 'b'could'',\nNearest to 'b'not'': 'b'it'', 'b'also'', 'b'there'', 'b'they'', 'b'to'', 'b'abv'',\nNearest to 'b'this'': 'b'it'', 'b'the'', 'b'which'', 'b'that'', 'b'akita'', 'b'a'',\nNearest to 'b'being'': 'b'akh'', 'b'any'', 'b'lumi'', 'b'entropy'', 'b'dead'', 'b'sedgwick'',\nNearest to 'b'zero'': 'b'five'', 'b'seven'', 'b'six'', 'b'eight'', 'b'nine'', 'b'four'',\nNearest to 'b'the'': 'b'a'', 'b'their'', 'b'its'', 'b'this'', 'b'his'', 'b'reginae'',\nNearest to 'b'although'': 'b'while'', 'b'was'', 'b'abitibi'', 'b'does'', 'b'dasyprocta'', 'b'gaming'',\nNearest to 'b'after'': 'b'four'', 'b'at'', 'b'six'', 'b'and'', 'b'if'', 'b'replace'',\nNearest to 'b'found'': 'b'biochemist'', 'b'trinomial'', 'b'sentenced'', 'b'trek'', 'b'austin'', 'b'cistercian'',\nNearest to 'b'name'': 'b'agouti'', 'b'appearance'', 'b'product'', 'b'pixel'', 'b'term'', 'b'ari'',\nNearest to 'b'same'': 'b'opus'', 'b'through'', 'b'find'', 'b'akita'', 'b'to'', 'b'last'',\nNearest to 'b'while'': 'b'and'', 'b'although'', 'b'is'', 'b'started'', 'b'in'', 'b'bolt'',\nNearest to 'b'john'': 'b'bomb'', 'b'paxton'', 'b'henri'', 'b'fifteen'', 'b'reliance'', 'b'strata'',\nNearest to 'b'life'': 'b'bos'', 'b'abakan'', 'b'amo'', 'b'lydia'', 'b'msg'', 'b'heywood'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 42000 is 5.324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 44000 is 5.424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 46000 is 5.286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 48000 is 5.035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 50000 is 5.165\nNearest to 'b'a'': 'b'the'', 'b'akita'', 'b'sotho'', 'b'albuquerque'', 'b'alpina'', 'b'anacharsis'',\nNearest to 'b'series'': 'b'cpc'', 'b'footsteps'', 'b'fictitious'', 'b'rick'', 'b'umayyad'', 'b'matter'',\nNearest to 'b'however'': 'b'and'', 'b'but'', 'b'that'', 'b'agouti'', 'b'imaginary'', 'b'reginae'',\nNearest to 'b'then'': 'b'agouti'', 'b'that'', 'b'hyperbolic'', 'b'unofficially'', 'b'reginae'', 'b'akita'',\nNearest to 'b'were'': 'b'are'', 'b'was'', 'b'is'', 'b'have'', 'b'had'', 'b'be'',\nNearest to 'b'in'': 'b'on'', 'b'at'', 'b'and'', 'b'from'', 'b'through'', 'b'agouti'',\nNearest to 'b'music'': 'b'trinomial'', 'b'backward'', 'b'compressibility'', 'b'recitative'', 'b'thermometer'', 'b'solon'',\nNearest to 'b'many'': 'b'some'', 'b'these'', 'b'recitative'', 'b'several'', 'b'administrators'', 'b'other'',\nNearest to 'b't'': 'b'dewey'', 'b'reasonably'', 'b'amalthea'', 'b'warring'', 'b'we'', 'b'also'',\nNearest to 'b'each'': 'b'their'', 'b'the'', 'b'armageddon'', 'b'indexing'', 'b'some'', 'b'agra'',\nNearest to 'b'have'': 'b'had'', 'b'be'', 'b'has'', 'b'are'', 'b'were'', 'b'amalthea'',\nNearest to 'b'university'': 'b'couplet'', 'b'raped'', 'b'austria'', 'b'harvesting'', 'b'topological'', 'b'wins'',\nNearest to 'b'term'': 'b'grimaldi'', 'b'name'', 'b'stresses'', 'b'hattie'', 'b'shaky'', 'b'abet'',\nNearest to 'b'until'': 'b'before'', 'b'from'', 'b'xv'', 'b'in'', 'b'abitibi'', 'b'compiler'',\nNearest to 'b'several'': 'b'many'', 'b'breath'', 'b'these'', 'b'some'', 'b'approved'', 'b'three'',\nNearest to 'b'united'': 'b'from'', 'b'prohibition'', 'b'bowhunting'', 'b'dasyprocta'', 'b'surat'', 'b'trinomial'',\nNearest to 'b'century'': 'b'keg'', 'b'innate'', 'b'invading'', 'b'eg'', 'b'cit'', 'b'methodist'',\nNearest to 'b'over'': 'b'charcot'', 'b'cunning'', 'b'activated'', 'b'microseconds'', 'b'outmoded'', 'b'clothed'',\nNearest to 'b'will'': 'b'would'', 'b'can'', 'b'could'', 'b'quakers'', 'b'belarusian'', 'b'may'',\nNearest to 'b'not'': 'b'also'', 'b'it'', 'b'they'', 'b'there'', 'b'to'', 'b'abv'',\nNearest to 'b'this'': 'b'it'', 'b'which'', 'b'the'', 'b'that'', 'b'prism'', 'b'akita'',\nNearest to 'b'being'': 'b'akh'', 'b'alienate'', 'b'any'', 'b'beeb'', 'b'entropy'', 'b'stitch'',\nNearest to 'b'zero'': 'b'eight'', 'b'seven'', 'b'five'', 'b'six'', 'b'nine'', 'b'four'',\nNearest to 'b'the'': 'b'its'', 'b'their'', 'b'his'', 'b'a'', 'b'this'', 'b'reginae'',\nNearest to 'b'although'': 'b'while'', 'b'is'', 'b'however'', 'b'does'', 'b'abitibi'', 'b'ellipse'',\nNearest to 'b'after'': 'b'before'', 'b'in'', 'b'six'', 'b'if'', 'b'seven'', 'b'at'',\nNearest to 'b'found'': 'b'biochemist'', 'b'trinomial'', 'b'cistercian'', 'b'sentenced'', 'b'trek'', 'b'austin'',\nNearest to 'b'name'': 'b'appearance'', 'b'agouti'', 'b'prism'', 'b'product'', 'b'term'', 'b'ari'',\nNearest to 'b'same'': 'b'opus'', 'b'through'', 'b'of'', 'b'last'', 'b'find'', 'b'akita'',\nNearest to 'b'while'': 'b'and'', 'b'although'', 'b'is'', 'b'akita'', 'b'started'', 'b'bolt'',\nNearest to 'b'john'': 'b'bomb'', 'b'henri'', 'b'paxton'', 'b'five'', 'b'reliance'', 'b'fifteen'',\nNearest to 'b'life'': 'b'bos'', 'b'amo'', 'b'abakan'', 'b'lydia'', 'b'msg'', 'b'stimulating'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 52000 is 5.179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 54000 is 5.120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 56000 is 5.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 58000 is 5.104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 60000 is 4.942\nNearest to 'b'a'': 'b'the'', 'b'akita'', 'b'sotho'', 'b'johansen'', 'b'anacharsis'', 'b'callithrix'',\nNearest to 'b'series'': 'b'callithrix'', 'b'michelob'', 'b'irt'', 'b'cpc'', 'b'footsteps'', 'b'rick'',\nNearest to 'b'however'': 'b'but'', 'b'and'', 'b'that'', 'b'although'', 'b'agouti'', 'b'which'',\nNearest to 'b'then'': 'b'that'', 'b'agouti'', 'b'hyperbolic'', 'b'akita'', 'b'ssbn'', 'b'androids'',\nNearest to 'b'were'': 'b'are'', 'b'was'', 'b'have'', 'b'had'', 'b'be'', 'b'is'',\nNearest to 'b'in'': 'b'at'', 'b'on'', 'b'from'', 'b'and'', 'b'through'', 'b'of'',\nNearest to 'b'music'': 'b'trinomial'', 'b'backward'', 'b'compressibility'', 'b'cebus'', 'b'recitative'', 'b'solon'',\nNearest to 'b'many'': 'b'some'', 'b'these'', 'b'several'', 'b'other'', 'b'recitative'', 'b'their'',\nNearest to 'b't'': 'b'dewey'', 'b'we'', 'b'reasonably'', 'b'warring'', 'b'also'', 'b'sparse'',\nNearest to 'b'each'': 'b'their'', 'b'the'', 'b'armageddon'', 'b'callithrix'', 'b'some'', 'b'intents'',\nNearest to 'b'have'': 'b'had'', 'b'has'', 'b'are'', 'b'be'', 'b'were'', 'b'amalthea'',\nNearest to 'b'university'': 'b'couplet'', 'b'mitch'', 'b'raped'', 'b'austria'', 'b'harvesting'', 'b'topological'',\nNearest to 'b'term'': 'b'name'', 'b'grimaldi'', 'b'stresses'', 'b'hattie'', 'b'abet'', 'b'enjoined'',\nNearest to 'b'until'': 'b'before'', 'b'xv'', 'b'from'', 'b'in'', 'b'abitibi'', 'b'is'',\nNearest to 'b'several'': 'b'many'', 'b'breath'', 'b'these'', 'b'some'', 'b'three'', 'b'approved'',\nNearest to 'b'united'': 'b'from'', 'b'bnetd'', 'b'dasyprocta'', 'b'prohibition'', 'b'callithrix'', 'b'trinomial'',\nNearest to 'b'century'': 'b'keg'', 'b'innate'', 'b'invading'', 'b'eg'', 'b'buckyballs'', 'b'cit'',\nNearest to 'b'over'': 'b'charcot'', 'b'cunning'', 'b'activated'', 'b'microseconds'', 'b'in'', 'b'outmoded'',\nNearest to 'b'will'': 'b'would'', 'b'can'', 'b'could'', 'b'may'', 'b'quakers'', 'b'must'',\nNearest to 'b'not'': 'b'also'', 'b'they'', 'b'it'', 'b'to'', 'b'there'', 'b'alamein'',\nNearest to 'b'this'': 'b'it'', 'b'which'', 'b'the'', 'b'that'', 'b'prism'', 'b'akita'',\nNearest to 'b'being'': 'b'callithrix'', 'b'akh'', 'b'any'', 'b'alienate'', 'b'wct'', 'b'entropy'',\nNearest to 'b'zero'': 'b'eight'', 'b'six'', 'b'five'', 'b'seven'', 'b'four'', 'b'nine'',\nNearest to 'b'the'': 'b'their'', 'b'its'', 'b'a'', 'b'cebus'', 'b'reginae'', 'b'this'',\nNearest to 'b'although'': 'b'while'', 'b'however'', 'b'colloids'', 'b'but'', 'b'does'', 'b'when'',\nNearest to 'b'after'': 'b'before'', 'b'tamarin'', 'b'in'', 'b'without'', 'b'at'', 'b'cebus'',\nNearest to 'b'found'': 'b'biochemist'', 'b'cebus'', 'b'trinomial'', 'b'sentenced'', 'b'cistercian'', 'b'cancel'',\nNearest to 'b'name'': 'b'appearance'', 'b'agouti'', 'b'prism'', 'b'term'', 'b'ari'', 'b'product'',\nNearest to 'b'same'': 'b'through'', 'b'last'', 'b'callithrix'', 'b'of'', 'b'opus'', 'b'akita'',\nNearest to 'b'while'': 'b'and'', 'b'although'', 'b'but'', 'b'ssbn'', 'b'tamarin'', 'b'or'',\nNearest to 'b'john'': 'UNK', 'b'bomb'', 'b'henri'', 'b'paxton'', 'b'averse'', 'b'tamarin'',\nNearest to 'b'life'': 'b'bos'', 'b'callithrix'', 'b'abakan'', 'b'amo'', 'b'lydia'', 'b'stimulating'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 62000 is 4.791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 64000 is 4.803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 66000 is 4.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 68000 is 4.929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 70000 is 4.779\nNearest to 'b'a'': 'b'akita'', 'b'the'', 'b'sotho'', 'b'mitral'', 'b'johansen'', 'b'callithrix'',\nNearest to 'b'series'': 'b'michelob'', 'b'callithrix'', 'b'irt'', 'b'fictitious'', 'b'rick'', 'b'footsteps'',\nNearest to 'b'however'': 'b'but'', 'b'although'', 'b'that'', 'b'which'', 'b'and'', 'b'though'',\nNearest to 'b'then'': 'b'agouti'', 'b'that'', 'b'hyperbolic'', 'b'akita'', 'b'it'', 'b'unofficially'',\nNearest to 'b'were'': 'b'are'', 'b'was'', 'b'have'', 'b'had'', 'b'be'', 'b'been'',\nNearest to 'b'in'': 'b'at'', 'b'from'', 'b'on'', 'b'during'', 'b'through'', 'b'since'',\nNearest to 'b'music'': 'b'backward'', 'b'trinomial'', 'b'compressibility'', 'b'cebus'', 'b'recitative'', 'b'thermometer'',\nNearest to 'b'many'': 'b'some'', 'b'these'', 'b'several'', 'b'other'', 'b'recitative'', 'b'thaler'',\nNearest to 'b't'': 'b'dewey'', 'b'we'', 'b'reasonably'', 'b'warring'', 'b'sparse'', 'b'suffix'',\nNearest to 'b'each'': 'b'the'', 'b'their'', 'b'armageddon'', 'b'thaler'', 'b'callithrix'', 'b'mitral'',\nNearest to 'b'have'': 'b'had'', 'b'has'', 'b'are'', 'b'were'', 'b'be'', 'b'amalthea'',\nNearest to 'b'university'': 'b'couplet'', 'b'mitch'', 'b'raped'', 'b'harvesting'', 'b'austria'', 'b'topological'',\nNearest to 'b'term'': 'b'name'', 'b'stresses'', 'b'grimaldi'', 'b'hattie'', 'b'shaky'', 'b'agouti'',\nNearest to 'b'until'': 'b'before'', 'b'in'', 'b'xv'', 'b'from'', 'b'abitibi'', 'b'four'',\nNearest to 'b'several'': 'b'many'', 'b'these'', 'b'breath'', 'b'some'', 'b'three'', 'b'members'',\nNearest to 'b'united'': 'b'from'', 'b'bnetd'', 'b'dasyprocta'', 'b'surat'', 'b'prohibition'', 'b'bowhunting'',\nNearest to 'b'century'': 'b'keg'', 'b'innate'', 'b'invading'', 'b'eg'', 'b'buckyballs'', 'b'refectory'',\nNearest to 'b'over'': 'b'charcot'', 'b'activated'', 'b'cunning'', 'b'microseconds'', 'b'four'', 'b'in'',\nNearest to 'b'will'': 'b'would'', 'b'can'', 'b'may'', 'b'could'', 'b'quakers'', 'b'must'',\nNearest to 'b'not'': 'b'also'', 'b'they'', 'b'it'', 'b'to'', 'b'usually'', 'b'there'',\nNearest to 'b'this'': 'b'which'', 'b'it'', 'b'the'', 'b'that'', 'b'prism'', 'b'thaler'',\nNearest to 'b'being'': 'b'callithrix'', 'b'entropy'', 'b'akh'', 'b'wct'', 'b'alienate'', 'b'beeb'',\nNearest to 'b'zero'': 'b'six'', 'b'eight'', 'b'five'', 'b'seven'', 'b'four'', 'b'nine'',\nNearest to 'b'the'': 'b'its'', 'b'their'', 'b'this'', 'b'thaler'', 'b'cebus'', 'b'reginae'',\nNearest to 'b'although'': 'b'while'', 'b'however'', 'b'where'', 'b'but'', 'b'colloids'', 'b'does'',\nNearest to 'b'after'': 'b'before'', 'b'tamarin'', 'b'in'', 'b'when'', 'b'at'', 'b'six'',\nNearest to 'b'found'': 'b'biochemist'', 'b'cebus'', 'b'trinomial'', 'b'footy'', 'b'thaler'', 'b'vantage'',\nNearest to 'b'name'': 'b'appearance'', 'b'agouti'', 'b'prism'', 'b'thaler'', 'b'term'', 'b'product'',\nNearest to 'b'same'': 'b'of'', 'b'last'', 'b'through'', 'b'callithrix'', 'b'opus'', 'b'akita'',\nNearest to 'b'while'': 'b'although'', 'b'and'', 'b'but'', 'b'tamarin'', 'b'or'', 'b'akita'',\nNearest to 'b'john'': 'b'henri'', 'b'bomb'', 'b'averse'', 'b'paxton'', 'UNK', 'b'tamarin'',\nNearest to 'b'life'': 'b'bos'', 'b'callithrix'', 'b'abakan'', 'b'lydia'', 'b'amo'', 'b'stimulating'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 72000 is 4.809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 74000 is 4.783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 76000 is 4.872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 78000 is 4.789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 80000 is 4.821\nNearest to 'b'a'': 'b'the'', 'b'mitral'', 'b'johansen'', 'b'akita'', 'b'albuquerque'', 'b'sotho'',\nNearest to 'b'series'': 'b'irt'', 'b'fictitious'', 'b'michelob'', 'b'footsteps'', 'b'rick'', 'b'matter'',\nNearest to 'b'however'': 'b'but'', 'b'although'', 'b'that'', 'b'though'', 'b'and'', 'b'agouti'',\nNearest to 'b'then'': 'b'agouti'', 'b'pontificia'', 'b'hyperbolic'', 'b'akita'', 'b'that'', 'b'cegep'',\nNearest to 'b'were'': 'b'are'', 'b'was'', 'b'have'', 'b'had'', 'b'be'', 'b'been'',\nNearest to 'b'in'': 'b'at'', 'b'during'', 'b'on'', 'b'from'', 'b'vec'', 'b'through'',\nNearest to 'b'music'': 'b'trinomial'', 'b'backward'', 'b'recitative'', 'b'cebus'', 'b'compressibility'', 'b'thermometer'',\nNearest to 'b'many'': 'b'some'', 'b'these'', 'b'several'', 'b'other'', 'b'all'', 'b'thaler'',\nNearest to 'b't'': 'b'dewey'', 'b'we'', 'b'warring'', 'b'spiritualist'', 'b'amalthea'', 'b'nobody'',\nNearest to 'b'each'': 'b'their'', 'b'the'', 'b'armageddon'', 'b'thaler'', 'b'callithrix'', 'b'mitral'',\nNearest to 'b'have'': 'b'had'', 'b'has'', 'b'were'', 'b'are'', 'b'be'', 'b'jump'',\nNearest to 'b'university'': 'b'dasyprocta'', 'b'callithrix'', 'b'cegep'', 'b'two'', 'b'aveiro'', 'b'austria'',\nNearest to 'b'term'': 'b'name'', 'b'hattie'', 'b'stresses'', 'b'grimaldi'', 'b'shaky'', 'b'abet'',\nNearest to 'b'until'': 'b'before'', 'b'in'', 'b'xv'', 'b'from'', 'b'abitibi'', 'b'juniper'',\nNearest to 'b'several'': 'b'many'', 'b'these'', 'b'some'', 'b'breath'', 'b'three'', 'b'members'',\nNearest to 'b'united'': 'b'bnetd'', 'b'from'', 'b'prohibition'', 'b'surat'', 'b'bowhunting'', 'b'dasyprocta'',\nNearest to 'b'century'': 'b'innate'', 'b'keg'', 'b'buckyballs'', 'b'invading'', 'b'eg'', 'b'refectory'',\nNearest to 'b'over'': 'b'pontificia'', 'b'charcot'', 'b'microseconds'', 'b'cunning'', 'b'activated'', 'b'outmoded'',\nNearest to 'b'will'': 'b'would'', 'b'can'', 'b'may'', 'b'could'', 'b'must'', 'b'quakers'',\nNearest to 'b'not'': 'b'also'', 'b'they'', 'b'it'', 'b'abv'', 'b'alamein'', 'b'to'',\nNearest to 'b'this'': 'b'it'', 'b'which'', 'b'the'', 'b'that'', 'b'thaler'', 'b'prism'',\nNearest to 'b'being'': 'b'selamat'', 'b'be'', 'b'callithrix'', 'b'entropy'', 'b'wct'', 'b'alienate'',\nNearest to 'b'zero'': 'b'eight'', 'b'five'', 'b'six'', 'b'seven'', 'b'four'', 'b'nine'',\nNearest to 'b'the'': 'b'their'', 'b'its'', 'b'his'', 'b'thaler'', 'b'reginae'', 'b'cebus'',\nNearest to 'b'although'': 'b'while'', 'b'however'', 'b'but'', 'b'where'', 'b'is'', 'b'colloids'',\nNearest to 'b'after'': 'b'before'', 'b'when'', 'b'in'', 'b'tamarin'', 'b'without'', 'b'at'',\nNearest to 'b'found'': 'b'biochemist'', 'b'cebus'', 'b'footy'', 'b'trinomial'', 'b'clodius'', 'b'used'',\nNearest to 'b'name'': 'b'appearance'', 'b'term'', 'b'prism'', 'b'agouti'', 'b'product'', 'b'thaler'',\nNearest to 'b'same'': 'b'last'', 'b'barberini'', 'b'of'', 'b'through'', 'b'callithrix'', 'b'straczynski'',\nNearest to 'b'while'': 'b'although'', 'b'or'', 'b'but'', 'b'and'', 'b'barberini'', 'b'tamarin'',\nNearest to 'b'john'': 'b'henri'', 'b'bomb'', 'b'averse'', 'UNK', 'b'paxton'', 'b'l'',\nNearest to 'b'life'': 'b'bos'', 'b'callithrix'', 'b'amo'', 'b'abakan'', 'b'stimulating'', 'b'lydia'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 82000 is 4.819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 84000 is 4.786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 86000 is 4.807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 88000 is 4.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 90000 is 4.764\nNearest to 'b'a'': 'b'akita'', 'b'the'', 'b'mitral'', 'b'johansen'', 'b'anacharsis'', 'b'sotho'',\nNearest to 'b'series'': 'b'irt'', 'b'michelob'', 'b'callithrix'', 'b'fictitious'', 'b'matter'', 'b'footsteps'',\nNearest to 'b'however'': 'b'but'', 'b'that'', 'b'although'', 'b'though'', 'b'and'', 'b'agouti'',\nNearest to 'b'then'': 'b'agouti'', 'b'hyperbolic'', 'UNK', 'b'pontificia'', 'b'akita'', 'b'that'',\nNearest to 'b'were'': 'b'are'', 'b'was'', 'b'have'', 'b'had'', 'b'be'', 'b'been'',\nNearest to 'b'in'': 'b'during'', 'b'at'', 'b'nine'', 'b'and'', 'b'cegep'', 'b'of'',\nNearest to 'b'music'': 'b'trinomial'', 'b'backward'', 'b'recitative'', 'b'cebus'', 'b'compressibility'', 'b'thermometer'',\nNearest to 'b'many'': 'b'some'', 'b'these'', 'b'several'', 'b'other'', 'b'all'', 'b'both'',\nNearest to 'b't'': 'b'dewey'', 'b'we'', 'b'frantz'', 'b'spiritualist'', 'b'reasonably'', 'b'nobody'',\nNearest to 'b'each'': 'b'the'', 'b'their'', 'b'armageddon'', 'b'thaler'', 'b'mitral'', 'b'callithrix'',\nNearest to 'b'have'': 'b'had'', 'b'has'', 'b'were'', 'b'are'', 'b'be'', 'b'valdemar'',\nNearest to 'b'university'': 'b'harvesting'', 'b'aveiro'', 'b'austria'', 'b'dasyprocta'', 'b'callithrix'', 'b'cegep'',\nNearest to 'b'term'': 'b'name'', 'b'hattie'', 'b'stresses'', 'b'grimaldi'', 'b'agouti'', 'b'shaky'',\nNearest to 'b'until'': 'b'before'', 'b'from'', 'b'five'', 'b'xv'', 'b'in'', 'b'for'',\nNearest to 'b'several'': 'b'many'', 'b'some'', 'b'these'', 'b'breath'', 'b'three'', 'b'indications'',\nNearest to 'b'united'': 'b'bnetd'', 'b'from'', 'b'prohibition'', 'b'surat'', 'b'quadrants'', 'b'dasyprocta'',\nNearest to 'b'century'': 'b'innate'', 'b'keg'', 'b'buckyballs'', 'b'invading'', 'b'eg'', 'b'consolidating'',\nNearest to 'b'over'': 'b'pontificia'', 'b'charcot'', 'b'microseconds'', 'b'cunning'', 'b'activated'', 'b'about'',\nNearest to 'b'will'': 'b'would'', 'b'can'', 'b'may'', 'b'could'', 'b'must'', 'b'shall'',\nNearest to 'b'not'': 'b'they'', 'b'also'', 'b'alamein'', 'b'we'', 'b'it'', 'b'usually'',\nNearest to 'b'this'': 'b'it'', 'b'which'', 'b'the'', 'b'that'', 'b'prism'', 'b'flightless'',\nNearest to 'b'being'': 'b'selamat'', 'b'be'', 'b'callithrix'', 'b'dead'', 'b'tamarin'', 'b'alienate'',\nNearest to 'b'zero'': 'b'eight'', 'b'five'', 'b'seven'', 'b'six'', 'b'nine'', 'b'four'',\nNearest to 'b'the'': 'b'its'', 'b'their'', 'b'thaler'', 'b'his'', 'b'this'', 'b'reginae'',\nNearest to 'b'although'': 'b'while'', 'b'however'', 'b'but'', 'b'where'', 'b'does'', 'b'is'',\nNearest to 'b'after'': 'b'before'', 'b'when'', 'b'without'', 'b'six'', 'b'at'', 'b'tamarin'',\nNearest to 'b'found'': 'b'used'', 'b'footy'', 'b'biochemist'', 'b'cebus'', 'b'clodius'', 'b'trinomial'',\nNearest to 'b'name'': 'b'appearance'', 'b'term'', 'b'product'', 'b'prism'', 'b'agouti'', 'b'nebraska'',\nNearest to 'b'same'': 'b'of'', 'b'last'', 'b'barberini'', 'b'through'', 'b'callithrix'', 'b'straczynski'',\nNearest to 'b'while'': 'b'although'', 'b'and'', 'b'but'', 'b'tamarin'', 'b'barberini'', 'b'in'',\nNearest to 'b'john'': 'b'henri'', 'b'bomb'', 'b'averse'', 'b'l'', 'b'pontificia'', 'UNK',\nNearest to 'b'life'': 'b'bos'', 'b'callithrix'', 'b'amo'', 'b'abakan'', 'b'stimulating'', 'b'lydia'',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 92000 is 4.692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 94000 is 4.618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 96000 is 4.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 98000 is 4.633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 100000 is 4.668\nNearest to 'b'a'': 'b'the'', 'b'akita'', 'b'sotho'', 'b'mitral'', 'b'albuquerque'', 'b'johansen'',\nNearest to 'b'series'': 'b'michelob'', 'b'irt'', 'b'callithrix'', 'b'matter'', 'b'fictitious'', 'b'footsteps'',\nNearest to 'b'however'': 'b'but'', 'b'that'', 'b'although'', 'b'and'', 'b'though'', 'b'thaler'',\nNearest to 'b'then'': 'UNK', 'b'agouti'', 'b'cleve'', 'b'pontificia'', 'b'hyperbolic'', 'b'akita'',\nNearest to 'b'were'': 'b'are'', 'b'have'', 'b'was'', 'b'had'', 'b'be'', 'b'been'',\nNearest to 'b'in'': 'b'at'', 'b'during'', 'b'on'', 'b'within'', 'b'from'', 'b'crandall'',\nNearest to 'b'music'': 'b'trinomial'', 'b'recitative'', 'b'compressibility'', 'b'backward'', 'b'cebus'', 'b'thermometer'',\nNearest to 'b'many'': 'b'some'', 'b'these'', 'b'several'', 'b'other'', 'b'all'', 'b'both'',\nNearest to 'b't'': 'b'dewey'', 'b'we'', 'b'frantz'', 'b'spiritualist'', 'b'nobody'', 'b'sparse'',\nNearest to 'b'each'': 'b'the'', 'b'their'', 'b'armageddon'', 'b'thaler'', 'b'any'', 'b'indexing'',\nNearest to 'b'have'': 'b'had'', 'b'has'', 'b'were'', 'b'are'', 'b'be'', 'b'valdemar'',\nNearest to 'b'university'': 'b'harvesting'', 'b'austria'', 'b'aveiro'', 'b'dasyprocta'', 'b'callithrix'', 'b'mitch'',\nNearest to 'b'term'': 'b'name'', 'b'hattie'', 'b'grimaldi'', 'b'stresses'', 'b'spurs'', 'b'agouti'',\nNearest to 'b'until'': 'b'before'', 'b'from'', 'b'in'', 'b'five'', 'b'xv'', 'b'juniper'',\nNearest to 'b'several'': 'b'many'', 'b'some'', 'b'these'', 'b'breath'', 'b'both'', 'b'members'',\nNearest to 'b'united'': 'b'bnetd'', 'b'surat'', 'b'quadrants'', 'b'prohibition'', 'b'defector'', 'b'dasyprocta'',\nNearest to 'b'century'': 'b'innate'', 'b'keg'', 'b'buckyballs'', 'b'invading'', 'b'consolidating'', 'b'eg'',\nNearest to 'b'over'': 'b'pontificia'', 'b'charcot'', 'b'microseconds'', 'b'cunning'', 'b'activated'', 'b'finalist'',\nNearest to 'b'will'': 'b'would'', 'b'can'', 'b'may'', 'b'could'', 'b'must'', 'b'should'',\nNearest to 'b'not'': 'b'also'', 'b'they'', 'b'usually'', 'b'alamein'', 'b'abv'', 'b'it'',\nNearest to 'b'this'': 'b'it'', 'b'which'', 'b'the'', 'b'that'', 'b'thaler'', 'b'prism'',\nNearest to 'b'being'': 'b'selamat'', 'b'be'', 'b'him'', 'b'callithrix'', 'b'was'', 'b'tamarin'',\nNearest to 'b'zero'': 'b'eight'', 'b'five'', 'b'seven'', 'b'six'', 'b'four'', 'b'nine'',\nNearest to 'b'the'': 'b'their'', 'b'its'', 'b'his'', 'b'this'', 'b'thaler'', 'b'a'',\nNearest to 'b'although'': 'b'while'', 'b'however'', 'b'but'', 'b'and'', 'b'where'', 'b'when'',\nNearest to 'b'after'': 'b'before'', 'b'when'', 'b'without'', 'b'at'', 'b'during'', 'b'in'',\nNearest to 'b'found'': 'b'used'', 'b'footy'', 'b'cebus'', 'b'clodius'', 'b'stopped'', 'b'trinomial'',\nNearest to 'b'name'': 'b'term'', 'b'appearance'', 'b'agouti'', 'b'prism'', 'b'product'', 'b'thaler'',\nNearest to 'b'same'': 'b'last'', 'b'of'', 'b'barberini'', 'b'callithrix'', 'b'through'', 'b'straczynski'',\nNearest to 'b'while'': 'b'although'', 'b'and'', 'b'but'', 'b'when'', 'b'or'', 'b'barberini'',\nNearest to 'b'john'': 'b'henri'', 'b'george'', 'b'averse'', 'b'four'', 'b'five'', 'b'pontificia'',\nNearest to 'b'life'': 'b'bos'', 'b'callithrix'', 'b'amo'', 'b'stimulating'', 'b'abakan'', 'b'lydia'',\n"
     ]
    }
   ],
   "source": [
    "# Train! \n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "summary_writer = tf.summary.FileWriter('/tmp/tf_logs/word2vec', graph=sess.graph)\n",
    "average_loss = 0\n",
    "\n",
    "num_steps = 100001\n",
    "for iter in xrange(num_steps):\n",
    "    batch_inputs, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n",
    "    feed_dict = {train_inputs : batch_inputs, train_labels : batch_labels}\n",
    "    _, loss_val = sess.run([optm, loss], feed_dict=feed_dict)\n",
    "    average_loss += loss_val\n",
    "    \n",
    "    if iter % 2000 == 0:\n",
    "        average_loss /= 2000\n",
    "        print (\"Average loss at step %d is %.3f\" % (iter, average_loss)) \n",
    "    \n",
    "    if iter % 10000 == 0:\n",
    "        siml_val = sess.run(siml)\n",
    "        for i in xrange(valid_size): # Among valid set \n",
    "            valid_word = reverse_dictionary[valid_examples[i]]\n",
    "            top_k = 6 # number of nearest neighbors\n",
    "            nearest = (-siml_val[i, :]).argsort()[1:top_k+1]\n",
    "            log_str = \"Nearest to '%s':\" % valid_word\n",
    "            for k in xrange(top_k):\n",
    "                close_word = reverse_dictionary[nearest[k]] \n",
    "                log_str = \"%s '%s',\" % (log_str, close_word)\n",
    "            print(log_str) \n",
    "            \n",
    "# Final embeding \n",
    "final_embeddings = sess.run(normalized_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualize the embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_with_labels(low_dim_embs, labels, filename='tsne.png'):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), \"More labels than embeddings\"\n",
    "    plt.figure(figsize=(18, 18))  #in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i,:]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                 xy=(x, y),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "    #plt.show()\n",
    "    plt.savefig(\"examples.jpg\")##保存到本地\n",
    "# Plot\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "plot_only = 500\n",
    "low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only,:])\n",
    "labels = [reverse_dictionary[i] for i in xrange(plot_only)]\n",
    "plot_with_labels(low_dim_embs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}